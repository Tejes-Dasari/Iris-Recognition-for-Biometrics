{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to infer naming conventions for left and right eyes\n",
    "def infer_naming_conventions(directory):\n",
    "    left_files = glob(os.path.join(directory, \"left\", \"*.bmp\"))\n",
    "    right_files = glob(os.path.join(directory, \"right\", \"*.bmp\"))\n",
    "\n",
    "    left_pattern = os.path.basename(left_files[0]).replace(\"1.bmp\", \"{}.bmp\")\n",
    "    right_pattern = os.path.basename(right_files[0]).replace(\"1.bmp\", \"{}.bmp\")\n",
    "\n",
    "    return left_pattern, right_pattern\n",
    "\n",
    "# Function to load images from a given directory with inferred naming pattern\n",
    "def load_images(directory, left_pattern, right_pattern, num_images):\n",
    "    left_images = []\n",
    "    right_images = []\n",
    "\n",
    "    for i in range(1, num_images + 1):\n",
    "        left_path = glob(os.path.join(directory, \"left\", left_pattern.format(i)))[0]\n",
    "        right_path = glob(os.path.join(directory, \"right\", right_pattern.format(i)))[0]\n",
    "\n",
    "        left_img = load_img(left_path, target_size=(320, 240))\n",
    "        right_img = load_img(right_path, target_size=(320, 240))\n",
    "\n",
    "        left_img_array = img_to_array(left_img)\n",
    "        right_img_array = img_to_array(right_img)\n",
    "\n",
    "        left_images.append(left_img_array)\n",
    "        right_images.append(right_img_array)\n",
    "\n",
    "    return np.array(left_images), np.array(right_images)\n",
    "\n",
    "# Assuming you have 46 persons, repeat the process for each person and concatenate the data\n",
    "all_left_images = []\n",
    "all_right_images = []\n",
    "labels = []\n",
    "\n",
    "for person_id in range(1, 46):  # Assuming 46 persons\n",
    "    person_directory = os.path.join(\"MMU-Iris-Database\", str(person_id))\n",
    "\n",
    "    left_pattern, right_pattern = infer_naming_conventions(person_directory)\n",
    "\n",
    "    left_eye_images, right_eye_images = load_images(\n",
    "        person_directory,\n",
    "        left_pattern=left_pattern,\n",
    "        right_pattern=right_pattern,\n",
    "        num_images=5\n",
    "    )\n",
    "\n",
    "    # Create labels (person IDs)\n",
    "    person_labels = np.full((10,), person_id - 1)  # Adjust index to start from 0\n",
    "\n",
    "    all_left_images.append(left_eye_images)\n",
    "    all_right_images.append(right_eye_images)\n",
    "    labels.append(person_labels)\n",
    "\n",
    "# Concatenate data for all persons\n",
    "all_left_images = np.concatenate(all_left_images)\n",
    "all_right_images = np.concatenate(all_right_images)\n",
    "labels = np.concatenate(labels)\n",
    "\n",
    "# Combine left and right eye images\n",
    "all_images = np.concatenate([all_left_images, all_right_images], axis=0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deeper_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Dense (fully connected) layers\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Dropout for regularization\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(46, activation='softmax'))  # Assuming 46 classes (persons)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Assuming input shape is (128, 128, 3) for RGB images\n",
    "input_shape = (320, 240, 3)\n",
    "\n",
    "# Create the deeper CNN model\n",
    "deeper_cnn_model = create_deeper_cnn_model(input_shape)\n",
    "\n",
    "# Display the model summary\n",
    "deeper_cnn_model.summary()\n",
    "\n",
    "# Train the model\n",
    "history_deeper = deeper_cnn_model.fit(X_train, y_train, epochs=35, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
